datos_ce
summary(datos_clean$PMACONV)
summary(datos_clean$PMACONV)
hist(datos_clean$PMACONV)
hist(datos_clean$PMACONV %>% filter(datos_clean$PMACONV < -100000 & datos_clean$PMACONV > 100000))
coef(mod_glm)
sum(coef(mod_glm))
sum(coef(mod_glm), na.rm = TRUE)
max(coef(mod_glm), na.rm = TRUE)
plot(mod_glm$fitted.values)
plot(mod_glm$fitted.values, datos_clean$PMACONV)
library(tidyverse)
data <- read.csv("/home/daniel/Desktop/KaggleV2-May-2016.csv", header = TRUE)
head(data)
datos_clean <- data %>% select(-PatientId, -AppointmentID)
head(datos_clean)
summary(datos_clean)
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDat, into = c("Sched_day", "Sched_time", sep = "T"))
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDate, into = c("Sched_day", "Sched_time", sep = "T"))
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDay, into = c("Sched_day", "Sched_time", sep = "T"))
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDay, into = c("Sched_day", "Sched_time"), sep = "T")
summary(Datos_clean)
summary(datos_clean)
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDay, into = c("Sched_day", "Sched_time"), sep = "T") %>%
separate(AppointmentDay, into = c("App_day", "App_time"), sep = "T")
summary(datos_clean)
head(datos_clean)
datos_clean$Sched_day <- datos_clean$Sched_day %>% as.Date()
summary(datos_clean)
table(datos_clean$Sched_time)
library(stringr)
datos_clean$Sched_time %>% str_sub(-1,7)
datos_clean$Sched_time %>% str_sub(-1,1)
datos_clean$Sched_time %>% str_sub(-1,-1)
datos_clean$Sched_time %>% str_sub(1,-1)
datos_clean$Sched_time %>% str_sub(1,6)
datos_clean$Sched_time %>% str_sub(1,8)
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% as.Date.POSIXlt()
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% as.Date.POSIXlt
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8)
summary(datos_clean$Sched_time)
datos_clean$Sched_time
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% as.POSIXct(format="%H:%M:%S")
summary(datos_clean$Sched_time)
install.packages("chron")
library(chron)
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% chron
data <- read.csv("/home/daniel/Desktop/KaggleV2-May-2016.csv", header = TRUE)
head(data)
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDay, into = c("Sched_day", "Sched_time"), sep = "T") %>%
separate(AppointmentDay, into = c("App_day", "App_time"), sep = "T")
datos_clean$Sched_day <- datos_clean$Sched_day %>% as.Date()
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% chron
summary(datos_clean$Sched_time)
datos_clean$Sched_time
datos_clean$Sched_time %>% str_sub(1,8)
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% chron()
?chron
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% times %>% chron
summary(datos_clean)
datos_clean$Sched_time
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% chron
data <- read.csv("/home/daniel/Desktop/KaggleV2-May-2016.csv", header = TRUE)
head(data)
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDay, into = c("Sched_day", "Sched_time"), sep = "T") %>%
separate(AppointmentDay, into = c("App_day", "App_time"), sep = "T")
datos_clean$Sched_day <- datos_clean$Sched_day %>% as.Date()
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% chron
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% chron(times=.)
summary(datos_clean)
datos_clean$App_day <- datos_clean$App_day %>% as.Date()
datos_clean$App_time <- datos_clean$App_time %>% str_sub(1,8) %>% chron(times=.)
summary(datos_clean)
hist(datos_clean$Age)
datos_clean[,8:13] <- datos_clean[,8:13] %>% as.factor()
rm(mod_glm, mod_lm)
rm(fam)
datos_clean[,8:13] <- datos_clean[,8:13] %>% sapply(as.factor)
summary(datos_clean)
datos_clean[,8:13] <- datos_clean[,8:13] %>% sapply(factor)
summary(datos_clean)
datos_clean[,8:13] %>% sapply(as.factor)
datos_clean[,8:13] %>% lapply(as.factor)
datos_clean[,8:13] <- datos_clean[,8:13] %>% lapply(as.factor)
summary(datos_clean)
datos_clean <- datos_clean %>% mutate(days_between = App_day - Sched_day)
datos_clean$days_between
head(datos_clean)
datos_clean <- datos_clean %>% mutate(app_dow = strftime(App_day, '%A'))
datos_clean$app_dow
table(datos_clean$app_dow)
summary(datos_clean)
datos_clean <- datos_clean %>% mutate(app_dow = strftime(App_day, '%A')) %>% as.factor()
summary(datos_clean)
table(datos_clean$Age)
datos_clean$app_dow <- datos_clean$app_dow %>% as.factor()
summary(datos_clean)
datos_clean %>% datos_clean %>% select(-App_time)
datos_clean <- datos_clean %>% select(-App_time)
summary(datos_clean)
datos_clean <- datos_clean %>% filter(Age >= 0)
summary(datos_clean)
library(R2jags)
mod_glm <- glm(No.show ~ ., data = datos_clean)
datos_clean$No.show <- elseif(datos_clean$No.show == "Yes",1,0)
datos_clean$No.show <- ifelse(datos_clean$No.show == "Yes",1,0)
summary(datos_clean<)
summary(datos_clean)
datos_clean$No.show <- ifelse(datos_clean$No.show == "Yes",1,0) %>% as.factor()
summary(datos_clean)
data <- read.csv("/home/daniel/Desktop/KaggleV2-May-2016.csv", header = TRUE)
head(data)
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDay, into = c("Sched_day", "Sched_time"), sep = "T") %>%
separate(AppointmentDay, into = c("App_day", "App_time"), sep = "T")
datos_clean$Sched_day <- datos_clean$Sched_day %>% as.Date()
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% chron(times=.)
datos_clean$App_day <- datos_clean$App_day %>% as.Date()
datos_clean$App_time <- datos_clean$App_time %>% str_sub(1,8) %>% chron(times=.)
datos_clean[,8:13] <- datos_clean[,8:13] %>% lapply(as.factor)
datos_clean <- datos_clean %>% mutate(days_between = App_day - Sched_day)
datos_clean <- datos_clean %>% mutate(app_dow = strftime(App_day, '%A'))
datos_clean$app_dow <- datos_clean$app_dow %>% as.factor()
datos_clean <- datos_clean %>% select(-App_time)
datos_clean <- datos_clean %>% filter(Age >= 0)
datos_clean$No.show <- ifelse(datos_clean$No.show == "Yes",TRUE,FALSE) %>% as.factor()
summary(datos_clean)
mod_glm <- glm(No.show ~ ., data = datos_clean)
datos_clean$No.show <- ifelse(datos_clean$No.show == "Yes",TRUE,FALSE)
mod_glm <- glm(No.show ~ ., data = datos_clean)
?glm
mod_glm <- glm(No.show ~ ., data = datos_clean)
coef(mod_glm)
mod_glm <- glm(No.show ~ ., data = datos_clean, family = "binomial")
coef(mod_glm)
rm(mod_glm)
mod_glm <- glm(Survived ~.,family=binomial(link='logit'),data=train)
mod_glm <- glm(Survived ~.,family=binomial(link='logit'),data=datos_clean)
mod_glm <- glm(No.show ~.,family=binomial(link='logit'),data=datos_clean)
mod_lm <- lm(No.show ~ ., data = datos_clean)
coef(mod_lm)
summary(mod_glm)
plot(datos_clean$Age, datos_clean$No.show)
summary(datos_clean)
data <- read.csv("/home/daniel/Desktop/KaggleV2-May-2016.csv", header = TRUE)
head(data)
datos_clean <- data %>% select(-PatientId, -AppointmentID) %>% separate(ScheduledDay, into = c("Sched_day", "Sched_time"), sep = "T") %>%
separate(AppointmentDay, into = c("App_day", "App_time"), sep = "T")
datos_clean$Sched_day <- datos_clean$Sched_day %>% as.Date()
datos_clean$Sched_time <- datos_clean$Sched_time %>% str_sub(1,8) %>% chron(times=.)
datos_clean$App_day <- datos_clean$App_day %>% as.Date()
datos_clean$App_time <- datos_clean$App_time %>% str_sub(1,8) %>% chron(times=.)
datos_clean[,8:13] <- datos_clean[,8:13] %>% lapply(as.factor)
datos_clean <- datos_clean %>% mutate(days_between = App_day - Sched_day)
datos_clean <- datos_clean %>% mutate(app_dow = strftime(App_day, '%A'))
datos_clean$app_dow <- datos_clean$app_dow %>% as.factor()
datos_clean <- datos_clean %>% select(-App_time)
datos_clean <- datos_clean %>% filter(Age >= 0)
datos_clean$No.show <- ifelse(datos_clean$No.show == "Yes",TRUE,FALSE)
mod_glm <- glm(No.show ~.,family=binomial(link='logit'),data=datos_clean)
summary(mod_glm)
plot(datos_clean$Age, datos_clean$No.show)
summary(datos_clean)
datos_clean$days_between <- datos_clean$days_between %>% as.numeric()
summary(datos_clean)
mod_glm <- glm(No.show ~.,family=binomial(link='logit'),data=datos_clean)
summary(mod_glm)
rm(mod_glm, mod_lm)
rm(list=ls())
source('~/Desktop/db_noshow.R')
mod_glm$fitted.values
hist(mod_glm$fitted.values)
max(mod_glm$fitted.values)
summary(mod_glm$fitted.values)
View(datos_clean)
cov(datos_clean$No.show, mod_glm$fitted.values)
summary(mod_glm)
cov(datos_clean$Age, mod_glm$fitted.values)
plot(datos_clean$Age, mod_glm$fitted.values)
setwd("/home/daniel/Dropbox/Maestria Data Science/Semestre 1/Fundamentos Estadisticos/ProyectoFinal/est46111_datos")
datos <- read.csv("data_diabetes.csv")
datos <- datos %>% select(-code)
library(tidyverse)
datos <- datos %>% select(-code)
View(datos)
hist(datos$time)
View(datos)
summary(datos)
datos <- datos %>% mutate(disp = ifelse(time %in% c("08:00", "12:00", "18:00", "22:00"),"papel", "elec"))
summary(datos)
datos$disp
datos$disp <- datos$disp %>% as.factor()
summary(datos)
library(tidyverse)
library(ggplot2)
library(R2jags)
source("load.R")
source("clean.R")
# Cristian Challú y Daniel Sharp
# Tarea 8
library(tidyverse)
library(DAAG)
data(mtcars)
low_variability <- function(datos){
meds <- sapply(datos, median) # obtenemos las medianas de cada variable
IQR <- sapply(datos, function(x) quantile(x,.75) - quantile(x,.25)) # obtenemos el rango intercuartil para cada variable
plot(meds, IQR) # graficamos las medianas vs el rango
global <- mean(IQR)/6 # Obtenemos el rango intercuartil global, que nosotros definimos como la división de la media del rango intercuartil
# entre 6.
datos[,which(IQR>global)] # Filtramos los datos, manteniendo únicamente las columnas con rango intercuartil mayor al global (las más variables)
}
low_variability(mtcars)
low_variability <- function(datos){
meds <- sapply(datos, median) # obtenemos las medianas de cada variable
IQR <- sapply(datos, function(x) quantile(x,.75) - quantile(x,.25)) # obtenemos el rango intercuartil para cada variable
plot(meds, IQR)# graficamos las medianas vs el rango
title("Mediana vs Rango Intercuartil")
global <- mean(IQR)/6 # Obtenemos el rango intercuartil global, que nosotros definimos como la división de la media del rango intercuartil
# entre 6.
datos[,which(IQR>global)] # Filtramos los datos, manteniendo únicamente las columnas con rango intercuartil mayor al global (las más variables)
}
low_variability(mtcars)
correlation_fitering <- function(datos, threshold = 0.75){
cors <- cor(datos) # definimos la matriz de correlación de los datos
#cors[lower.tri(cors, diag = TRUE)]<-0
cors[cors==1]<-0 # hacemos cero los valores de la diagonal porque pueden crear problemas posteriormente
cors <- cors %>% apply(.,2,abs) # convertimos todas las correlaciones a positivo con el valor absoluto
variables <- c() # definimos un vector vacío para acumular las variables que vamos a desechar
while(max(cors) > threshold){  # While que cicla el proceso mientras haya correlaciones mayores a las definidas en el threshold.
aux <- (cors>=threshold) %>% apply(.,2,sum) # suma por columna el número de correlaciones mayores a 0.75
variables <- c(variables,names(which(aux==max(aux))[1])) # guarda la variable con mayor número de correlaciones mayores a 0.75,
# si hay dos iguales se queda con la primera, en el vector de variables
cors <- cors[-which(aux==max(aux))[1],-which(aux==max(aux))[1]] # quita la variable que se guardó en la línea anterior.
}
datos[,-which(names(datos) %in% variables)] # regresa el dataframe eliminando las variables altamente correlacionedas.
}
correlation_fitering(mtcars)
correlation_fitering <- function(datos, threshold = 0.5){
cors <- cor(datos) # definimos la matriz de correlación de los datos
#cors[lower.tri(cors, diag = TRUE)]<-0
cors[cors==1]<-0 # hacemos cero los valores de la diagonal porque pueden crear problemas posteriormente
cors <- cors %>% apply(.,2,abs) # convertimos todas las correlaciones a positivo con el valor absoluto
variables <- c() # definimos un vector vacío para acumular las variables que vamos a desechar
while(max(cors) > threshold){  # While que cicla el proceso mientras haya correlaciones mayores a las definidas en el threshold.
aux <- (cors>=threshold) %>% apply(.,2,sum) # suma por columna el número de correlaciones mayores a 0.75
variables <- c(variables,names(which(aux==max(aux))[1])) # guarda la variable con mayor número de correlaciones mayores a 0.75,
# si hay dos iguales se queda con la primera, en el vector de variables
cors <- cors[-which(aux==max(aux))[1],-which(aux==max(aux))[1]] # quita la variable que se guardó en la línea anterior.
}
datos[,-which(names(datos) %in% variables)] # regresa el dataframe eliminando las variables altamente correlacionedas.
}
correlation_fitering(mtcars)
correlation_fitering <- function(datos, threshold = 0.75){
cors <- cor(datos) # definimos la matriz de correlación de los datos
#cors[lower.tri(cors, diag = TRUE)]<-0
cors[cors==1]<-0 # hacemos cero los valores de la diagonal porque pueden crear problemas posteriormente
cors <- cors %>% apply(.,2,abs) # convertimos todas las correlaciones a positivo con el valor absoluto
variables <- c() # definimos un vector vacío para acumular las variables que vamos a desechar
while(max(cors) > threshold){  # While que cicla el proceso mientras haya correlaciones mayores a las definidas en el threshold.
aux <- (cors>=threshold) %>% apply(.,2,sum) # suma por columna el número de correlaciones mayores a 0.75
variables <- c(variables,names(which(aux==max(aux))[1])) # guarda la variable con mayor número de correlaciones mayores a 0.75,
# si hay dos iguales se queda con la primera, en el vector de variables
cors <- cors[-which(aux==max(aux))[1],-which(aux==max(aux))[1]] # quita la variable que se guardó en la línea anterior.
}
datos[,-which(names(datos) %in% variables)] # regresa el dataframe eliminando las variables altamente correlacionedas.
}
correlation_fitering(mtcars)
# este proceso es idéntico al de la función anterior.
cors <- cor(mtcars)
cors[cors==1]<-0
cors <- cors %>% apply(.,2,abs)
variables <- c()
aux <- cors[which(cors[,1] == max(cors[,1])),-1] # se obtiene la matriz de correlaciones contra la variable dependiente
aux
variables <- c(variables,names(which(aux>=threshold))) # se guarda las variable con correlación con la dependiente mayores al threshold
threshold=0.75
variables <- c(variables,names(which(aux>=threshold))) # se guarda las variable con correlación con la dependiente mayores al threshold
variables
aux_var <- c(which(cors[,1] == max(cors[,1])), which(aux>=threshold)+1)  # se obtienen las variables altamente correlacionadas con la variable
aux_var
# seleccionada en el paso anterior
cors <- cors[-aux_var,-aux_var] # se obtiene la matriz de correlaciones sin las variables eliminadas en el paso anterior
FCB_filtering(mtcars)
FCB_filtering <- function(datos, threshold = 0.75){
# este proceso es idéntico al de la función anterior.
cors <- cor(mtcars)
cors[cors==1]<-0
cors <- cors %>% apply(.,2,abs)
variables <- c()
while(length(cors)>1){ # cicla las siguientes funciones hasta que la matriz de correlaciones tenga un solo elemento
aux <- cors[which(cors[,1] == max(cors[,1])),-1] # se obtiene la matriz de correlaciones contra la variable dependiente
variables <- c(variables,names(which(aux>=threshold))) # se guardan las variables con correlación con la dependiente mayores al threshold
aux_var <- c(which(cors[,1] == max(cors[,1])), which(aux>=threshold)+1)  # se obtienen las variables altamente correlacionadas con la variable
# seleccionada en el paso anterior
cors <- cors[-aux_var,-aux_var] # se obtiene la matriz de correlaciones sin las variables eliminadas en el paso anterior
}
datos[,-which(names(datos) %in% variables)] # se regresa la base de datos únicamente con las variables de interés.
}
FCB_filtering(mtcars)
FCB_filtering <- function(datos, threshold = 0.75){
# este proceso es idéntico al de la función anterior.
cors <- cor(datos)
cors[cors==1]<-0
cors <- cors %>% apply(.,2,abs)
variables <- c()
while(length(cors)>1){ # cicla las siguientes funciones hasta que la matriz de correlaciones tenga un solo elemento
aux <- cors[which(cors[,1] == max(cors[,1])),-1] # se obtiene la matriz de correlaciones contra la variable dependiente
variables <- c(variables,names(which(aux>=threshold))) # se guardan las variables con correlación con la dependiente mayores al threshold
aux_var <- c(which(cors[,1] == max(cors[,1])), which(aux>=threshold)+1)  # se obtienen las variables altamente correlacionadas con la variable
# seleccionada en el paso anterior
cors <- cors[-aux_var,-aux_var] # se obtiene la matriz de correlaciones sin las variables eliminadas en el paso anterior
}
datos[,-which(names(datos) %in% variables)] # se regresa la base de datos únicamente con las variables de interés.
}
FCB_filtering(mtcars, 0.75)
forward_filtering <- function(datos, mejora_min=0.05){
vars_unused <- names(datos)[-1] # se crea un vector con todas las variables menos la dependiente
vars_used <- c() # se crea un vector vacío para acumular las variables seleccionadas posteriormente
min_error <- 10000000000000000 # se inicializa el error mínimo con un valor alto
dif <- 1 # se inicializa la variable dif
while(dif > mejora_min){ # mientras
err <- c()
for(i in 1:(length(vars_unused))){
vars <- datos[,c("mpg", vars_used,vars_unused[i])]
suppressMessages(mod <- cv.lm(vars, mpg~., m=5))
err <- c(err,attr(mod,"ms"))
}
dif <- min_error - min(err)
min_error <- min(err)
if(dif>mejora_min){
vars_used <- c(vars_used,vars_unused[which(err == min_error)])
vars_unused <- vars_unused[-which(err == min_error)]
}
}
datos[,c("mpg",vars_used)]
}
forward_filtering(mtcars)
forward_filtering <- function(datos, mejora_min=0.05){
vars_unused <- names(datos)[-1] # se crea un vector con todas las variables menos la dependiente
vars_used <- c() # se crea un vector vacío para acumular las variables seleccionadas posteriormente
min_error <- 10000000000000000 # se inicializa el error mínimo con un valor alto
dif <- 1 # se inicializa la variable dif
while(dif > mejora_min){ # mientras
err <- c() # se crea un vector vacío para los errores
for(i in 1:(length(vars_unused))){
vars <- datos[,c("mpg", vars_used,vars_unused[i])]
invisible(capture.output(mod <- cv.lm(vars, mpg~., m=5)))
err <- c(err,attr(mod,"ms"))
}
dif <- min_error - min(err)
min_error <- min(err)
if(dif>mejora_min){
vars_used <- c(vars_used,vars_unused[which(err == min_error)])
vars_unused <- vars_unused[-which(err == min_error)]
}
}
datos[,c("mpg",vars_used)]
}
forward_filtering(mtcars)
forward_filtering <- function(datos, mejora_min=0.05, cv = 5, var_dep = "mpg"){
vars_unused <- names(datos)[-1] # se crea un vector con todas las variables menos la dependiente
vars_used <- c() # se crea un vector vacío para acumular las variables seleccionadas posteriormente
min_error <- 10000000000000000 # se inicializa el error mínimo con un valor alto
dif <- 1 # se inicializa la variable dif
while(dif > mejora_min){ # mientras
err <- c() # se crea un vector vacío para los errores
for(i in 1:(length(vars_unused))){ # iteramos para todas las variables
vars <- datos[,c(var_dep, vars_used,vars_unused[i])] # creamos dataframe con la variable target y las variables explicativas para la iteración
invisible(capture.output(mod <- cv.lm(vars, mpg~., m=cv))) # ejecutamos la función de regresión lineal con validación cruzada ogual a 5
err <- c(err,attr(mod,"ms"))
}
dif <- min_error - min(err)
min_error <- min(err)
if(dif>mejora_min){
vars_used <- c(vars_used,vars_unused[which(err == min_error)])
vars_unused <- vars_unused[-which(err == min_error)]
}
}
datos[,c("mpg",vars_used)]
}
forward_filtering(mtcars)
forward_filtering <- function(datos, mejora_min=0.05, cv = 5, var_dep = "mpg"){
vars_unused <- names(datos)[-1] # se crea un vector con todas las variables menos la dependiente
vars_used <- c() # se crea un vector vacío para acumular las variables seleccionadas posteriormente
min_error <- 10000000000000000 # se inicializa el error mínimo con un valor alto
dif <- 1 # se inicializa la variable dif
while(dif > mejora_min){ # mientras
err <- c() # se crea un vector vacío para los errores
for(i in 1:(length(vars_unused))){ # iteramos para todas las variables
vars <- datos[,c(var_dep, vars_used,vars_unused[i])] # creamos dataframe con la variable target y las variables explicativas para la iteración
invisible(capture.output(mod <- cv.lm(vars, mpg~., m=cv))) # ejecutamos la función de regresión lineal con validación cruzada, se utilizan
# las funciones de invisible y capture output para evitar que imprima los resúmenes en la consola.
err <- c(err,attr(mod,"ms")) # guardamos los errores de validación cruzada para cada interación
}
dif <- min_error - min(err) # calculamos la mejora
min_error <- min(err) # sobrescribimos el error mínimo con el nuevo
# Si la mejora por agregar una variable fue mayor a la mejora mínima agregamos esa variable al vector de variables usadas
if(dif>mejora_min){
vars_used <- c(vars_used,vars_unused[which(err == min_error)])
vars_unused <- vars_unused[-which(err == min_error)]
}
}
datos[,c(var_dep,vars_used)] # se regresa la base de datos únicamente con las variables seleccionadas
}
forward_filtering(mtcars)
library(tidyvserse)
library(R2jags)
datos <- read.csv("~/Desktop/WineRegAv/winequality-red.csv")
View(datos)
View(datos)
lm(data = datos, quality ~ .)
summary(lm(data = datos, quality ~ .))
datos_s <- scale(datos) %>% as.data
datos_s <- scale(datos) %>% as.data.frame()
library(tidyvserse)
library(tidyverse)
datos_s <- scale(datos) %>% as.data.frame()
summary(lm(data = datos, quality ~ .))
summary(lm(data = datos_s, quality ~ .))
View(datos)
plot(datos)
?gbm
library(tidyverse)
library(stringr)
library(keras)
library(MLmetrics)
library(gbm)
?gbm
library(tidyverse)
library(R2jags)
setwd("~/Desktop/AvRegRetail/")
datos <- read.csv("data_set.csv")
vtas <- read.csv("sales_data_set.csv")
unique(datos$Store)
datos <- datos %>% filter(Store == 7)
vtas <- vtas %>% filter(Store == 7)
vtas <- vtas %>% group_by(Store, Date) %>% summarise(sales = sum(Weekly_Sales))
datos <- inner_join(datos, vtas, by=c("Store", "Date"))
datos$IsHoliday <- as.numeric(datos$IsHoliday)
datos$Date <- datos$Date %>% as.Date(., format = "%d/%m/%Y")
rm(vtas)
dates <- datos$Date
datos <- datos%>% arrange(Date) %>% mutate(date = 1:nrow(datos)) %>% select(-Date)
datos <- datos %>% select(-Store)
datos[is.na(datos[,3]),3] <- 0
datos[is.na(datos[,4]),4] <- 0
datos[is.na(datos[,5]),5] <- 0
datos[is.na(datos[,6]),6] <- 0
datos[is.na(datos[,7]),7] <- 0
summary(datos)
plot(datos)
library(tidyverse)
library(R2jags)
setwd("~/Desktop/AvRegRetail/")
datos <- read.csv("data_set.csv")
vtas <- read.csv("sales_data_set.csv")
unique(datos$Store)
datos <- datos %>% filter(Store == 7)
vtas <- vtas %>% filter(Store == 7)
vtas <- vtas %>% group_by(Store, Date) %>% summarise(sales = sum(Weekly_Sales))
datos <- inner_join(datos, vtas, by=c("Store", "Date"))
datos$IsHoliday <- as.numeric(datos$IsHoliday)
datos$Date <- datos$Date %>% as.Date(., format = "%d/%m/%Y")
rm(vtas)
dates <- datos$Date
datos <- datos%>% arrange(Date) %>% mutate(date = 1:nrow(datos)) %>% select(-Date)
datos <- datos %>% select(-Store)
datos[is.na(datos[,3]),3] <- 0
datos[is.na(datos[,4]),4] <- 0
datos[is.na(datos[,5]),5] <- 0
datos[is.na(datos[,6]),6] <- 0
datos[is.na(datos[,7]),7] <- 0
summary(datos)
plot(datos)
datos$sales <- datos$sales/max(datos$sales)
datos[,c(1:10,12)] <- scale(datos[,c(1:10,12)]) %>% as.data.frame()
n <- nrow(datos)
data<-list("n"=n,"y"=datos$sales,"x"=datos[,c(1:10,12)])
inits<-function(){list(intercept=0, beta=rep(0,11), yf=rep(1,n), alpha=1)}
#-Parámetros a monitorear-
# Normal
#parameters<-c("beta", "tau", "yf", "mu")
# Gamma
parameters<-c("intercept","beta", "yf", "mu")
mod.sim<-jags(data,inits,parameters,model.file="Gamma.txt",
n.iter=10000,n.chains=1,n.burnin=1000, n.thin = 1)
out.sum<-mod.sim$BUGSoutput$summary
out<-mod.sim$BUGSoutput$sims.list
out.dic<-mod.sim$BUGSoutput$DIC
print(paste0("DIC: ",out.dic))
out.yf<-out.sum[grep("yf",rownames(out.sum)),]
print(paste0("PseudoR2: ", stats::cor(datos$sales, out.yf[,1])^2))
print("Beta:")
out.sum[grep("beta",rownames(out.sum)),c(1,3,7)]
z<-out$beta[,5]
par(mfrow=c(2,2))
plot(z,type="l")
plot(cumsum(z)/(1:length(z)),type="l")
hist(z,freq=FALSE)
acf(z)
print("Y pred Hombres:")
out.sum.t<-out.sum[grep("yf",rownames(out.sum)),c(1,3,7)]
print(out.sum.t)
out.yf<-out.sum[grep("yf",rownames(out.sum)),]
or<-order(datos$date)
ymin<-min(datos$sales,out.yf[,c(1,3,7)])
ymax<-max(datos$sales,out.yf[,c(1,3,7)])
par(mfrow=c(1,1))
plot(datos$date,datos$sales,ylim=c(ymin,ymax))
lines(datos$date[or],out.yf[or,1],lwd=2,col=2)
lines(datos$date[or],out.yf[or,3],lty=2,col=2)
lines(datos$date[or],out.yf[or,7],lty=2,col=2)
shiny::runApp('~/Dropbox/Maestria Data Science/Semestre 1/Minería de Datos/ExamenMineria')
