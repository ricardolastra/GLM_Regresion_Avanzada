---
title: "Ejercicio 7"
author: "Ricardo Lastra"
date: "07 de Noviembre de 2017"
output:
  html_document: default
---

```{r, include=FALSE}
library(mrbsizeR)
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

&nbsp;

Producción de leche (Congdon, 2001). Se tienen los datos
anuales de producción de leche (Yt) en lbs109, y número de vacas (xt) en unidades106, en el período de 1970 a 1982.

El modelo sugerido para estos datos es: para t1,2,...,13

&nbsp;

$$
Observación:\ Y_{t}=\beta_{t}x_+\epsilon_{t},\epsilon_{t} \thicksim N(0,V^{-1})  \Rightarrow Y_{t} \thicksim N(\beta_t x_t,V^{-1}) \\
Evolución:\ \beta_{t}=\beta_{t-1}+\omega_{t},\omega_{t} \thicksim N(0,W^{-1}) \Rightarrow \beta_{t} \thicksim N(\beta_{t-1},W^{-1}) \\
$$

Además sugieren una varianza constante V1 y W0.05. 

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center", warning=F, error=F, message=F}
#By Ricardo Lastra
#Usamos en este ejercicio R2Jags
#install.packages("R2jags")
library(R2jags)

wdir<-getwd()
setwd(wdir)

#-------Funciones utiles----------
prob <- function(x){
  out <- min(length(x[x>0])/length(x),length(x[x<0])/length(x))
  out
}

#-Reading data-
milk<-read.table("http://allman.rhon.itam.mx/~lnieto/index_archivos/milk.txt",header=TRUE)
milk$t<-1970:1982
n<-nrow(milk)
or<-order(milk$x)
plot(milk$x[or],milk$y[or],type="l")
text(milk$x[or],milk$y[or],labels=milk$t[or],cex=0.5,col=2)
plot(milk$t,milk$y,type="l")
plot(milk$t,milk$x,type="l")
#-Defining data-
m<-2
data<-list("n"=n,"m"=m,"y"=scale(milk$y)[1:n],"x"=scale(milk$x)[1:n],"t"=scale(milk$t)[1:n])
```


&nbsp;

### Ejercicio B)

&nbsp;


Se pide realizar un ejercicio quitando y poniendo "0" en las distribuciones iniciales, donde se piensa que con esto ya no habra diferencia en los resultados del modelo normal y gamma.


&nbsp;


Modelo:


```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
inits<-function(){list(beta=rep(0,n+m),tau.y=1,yf1=rep(0,n+m))}
parameters<-c("beta","tau.y","tau.b","yf1")
ej7b.sim<-jags(data,inits,parameters,model.file="Ej7b.txt",
               n.iter=50000,n.chains=1,n.burnin=5000,n.thin=1)
```

&nbsp;

Usando:

model
{
Likelihood
Space eq.
for (i in 1:n) {
	y[i] ~ dnorm(mu[i],tau.y)
	mu[i]<-beta[i]
	}
State eq.
for (i in 2:n) {
	beta[i] ~ dnorm(mu.b[i],tau.b)
	mu.b[i] <- beta[i-1]
	}
Priors 
beta[1] ~ dnorm(0,0.001)
tau.b<- lam*tau.y
lam<-0.01
tau.y ~ dgamma(0.001,0.001)

Prediction 1:

for (i in 1:n) { yf1[i] ~ dnorm(mu[i],tau.y) }

Prediction 2:

for (i in (n+1):(n+m)) { 
	yf1[i] ~ dnorm(mu[i],tau.y)
	mu[i] <- beta[i]
	beta[i] ~ dnorm(mu.b[i],tau.b)
	mu.b[i] <- beta[i-1]
}

}

&nbsp;

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
out<-ej7b.sim$BUGSoutput$sims.list

z<-out$yf1[,1]
par(mfrow=c(2,2))
plot(z,type="l")
plot(cumsum(z)/(1:length(z)),type="l")
hist(z,freq=FALSE)
acf(z)
```

&nbsp;


```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#Resumen de estimadores
out.sum<-ej7b.sim$BUGSoutput$summary
#Tabla resumen
out.sum.t<-out.sum[grep("beta",rownames(out.sum)),c(1,3,7)]
out.sum.t<-cbind(out.sum.t,apply(out$beta,2,prob))
dimnames(out.sum.t)[[2]][4]<-"prob"
print(out.sum.t)
```

&nbsp;

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#DIC
out.dic<-ej7b.sim$BUGSoutput$DIC
print(out.dic)
```

&nbsp;

Predicciones:

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#Predictions
out.yf<-out.sum[grep("yf1",rownames(out.sum)),]
ymin<-min(data$y[1:(n-2)],out.yf[,c(1,3,7)])
ymax<-max(data$y[1:(n-2)],out.yf[,c(1,3,7)])
par(mfrow=c(1,1))
#t vs y
par(mfrow=c(1,1))
plot(data$t,data$y,type="b",col="grey80",ylim=c(ymin,ymax))
lines(data$t,out.yf[1:n,1],col=2)
lines(data$t,out.yf[1:n,3],col=2,lty=2)
lines(data$t,out.yf[1:n,7],col=2,lty=2)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),1],col=4)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),3],col=4,lty=2)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),7],col=4,lty=2)
```

&nbsp;


Medias:

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#betas
out.beta<-out.sum[grep("beta",rownames(out.sum)),]
ymin<-min(out.beta[,c(1,3,7)])
ymax<-max(out.beta[,c(1,3,7)])
plot(out.beta[,1],type="l",ylim=c(ymin,ymax))
lines(out.beta[,3],lty=2)
lines(out.beta[,7],lty=2)
```

&nbsp;


###Ejercicio aumentando el numero de "0's" en la a priori


&nbsp;

`NOTA`: Corremos el modelo poniendo 4 "0's" en las iniciales. Esto hace que sea menos informativa la **a priori** ya que el grado de conocimiento inicial es el menor de los parametros de estudio, esto determinara que los resultados esten menos sesgados. Revisando contra el modelo con 2 "o's", este modelo nos brinda una salida mucho mas justa, lo podemos observar en el DIC que se hace mas pequeño conforme incrementamos el numero de "0's".

&nbsp;


```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
inits<-function(){list(beta=rep(0,n+m),tau.y=1,yf1=rep(0,n+m))}
parameters<-c("beta","tau.y","tau.b","yf1")
ej7b_1.sim<-jags(data,inits,parameters,model.file="Ej7b_1.txt",
               n.iter=50000,n.chains=1,n.burnin=5000,n.thin=1)
```

&nbsp;


&nbsp;

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
out<-ej7b_1.sim$BUGSoutput$sims.list

z<-out$yf1[,1]
par(mfrow=c(2,2))
plot(z,type="l")
plot(cumsum(z)/(1:length(z)),type="l")
hist(z,freq=FALSE)
acf(z)
```

&nbsp;


```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#Resumen de estimadores
out.sum<-ej7b_1.sim$BUGSoutput$summary
#Tabla resumen
out.sum.t<-out.sum[grep("beta",rownames(out.sum)),c(1,3,7)]
out.sum.t<-cbind(out.sum.t,apply(out$beta,2,prob))
dimnames(out.sum.t)[[2]][4]<-"prob"
print(out.sum.t)
```

&nbsp;

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#DIC
out.dic<-ej7b_1.sim$BUGSoutput$DIC
print(out.dic)
```

&nbsp;

Predicciones:

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#Predictions
out.yf<-out.sum[grep("yf1",rownames(out.sum)),]
ymin<-min(data$y[1:(n-2)],out.yf[,c(1,3,7)])
ymax<-max(data$y[1:(n-2)],out.yf[,c(1,3,7)])
par(mfrow=c(1,1))
#t vs y
par(mfrow=c(1,1))
plot(data$t,data$y,type="b",col="grey80",ylim=c(ymin,ymax))
lines(data$t,out.yf[1:n,1],col=2)
lines(data$t,out.yf[1:n,3],col=2,lty=2)
lines(data$t,out.yf[1:n,7],col=2,lty=2)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),1],col=4)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),3],col=4,lty=2)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),7],col=4,lty=2)
```

&nbsp;


Medias:

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#betas
out.beta<-out.sum[grep("beta",rownames(out.sum)),]
ymin<-min(out.beta[,c(1,3,7)])
ymax<-max(out.beta[,c(1,3,7)])
plot(out.beta[,1],type="l",ylim=c(ymin,ymax))
lines(out.beta[,3],lty=2)
lines(out.beta[,7],lty=2)
```

&nbsp;

###Ejercicio aumentamos un "0" mas en la a priori


&nbsp;

`NOTA`: Corremos el modelo poniendo 5 "0's" en las iniciales. Lo anterior continua confirmado que el sesgo en los resultados dismunuyen, donde en este caso el DIC sigue siendo mas pequeño conforme el numero de "0's" aumenta.


&nbsp;


```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
inits<-function(){list(beta=rep(0,n+m),tau.y=1,yf1=rep(0,n+m))}
parameters<-c("beta","tau.y","tau.b","yf1")
ej7b_2.sim<-jags(data,inits,parameters,model.file="Ej7b_2.txt",
               n.iter=50000,n.chains=1,n.burnin=5000,n.thin=1)
```

&nbsp;


&nbsp;

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
out<-ej7b_2.sim$BUGSoutput$sims.list

z<-out$yf1[,1]
par(mfrow=c(2,2))
plot(z,type="l")
plot(cumsum(z)/(1:length(z)),type="l")
hist(z,freq=FALSE)
acf(z)
```

&nbsp;


```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#Resumen de estimadores
out.sum<-ej7b_2.sim$BUGSoutput$summary
#Tabla resumen
out.sum.t<-out.sum[grep("beta",rownames(out.sum)),c(1,3,7)]
out.sum.t<-cbind(out.sum.t,apply(out$beta,2,prob))
dimnames(out.sum.t)[[2]][4]<-"prob"
print(out.sum.t)
```

&nbsp;

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#DIC
out.dic<-ej7b_2.sim$BUGSoutput$DIC
print(out.dic)
```

&nbsp;

Predicciones:

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#Predictions
out.yf<-out.sum[grep("yf1",rownames(out.sum)),]
ymin<-min(data$y[1:(n-2)],out.yf[,c(1,3,7)])
ymax<-max(data$y[1:(n-2)],out.yf[,c(1,3,7)])
par(mfrow=c(1,1))
#t vs y
par(mfrow=c(1,1))
plot(data$t,data$y,type="b",col="grey80",ylim=c(ymin,ymax))
lines(data$t,out.yf[1:n,1],col=2)
lines(data$t,out.yf[1:n,3],col=2,lty=2)
lines(data$t,out.yf[1:n,7],col=2,lty=2)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),1],col=4)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),3],col=4,lty=2)
lines(data$t[n]:(data$t[n]+m),out.yf[n:(n+m),7],col=4,lty=2)
```

&nbsp;


Medias:

```{r fig.width=6, fig.height=4,echo=TRUE, fig.align = "center",warning=F, error=F, message=F}
#betas
out.beta<-out.sum[grep("beta",rownames(out.sum)),]
ymin<-min(out.beta[,c(1,3,7)])
ymax<-max(out.beta[,c(1,3,7)])
plot(out.beta[,1],type="l",ylim=c(ymin,ymax))
lines(out.beta[,3],lty=2)
lines(out.beta[,7],lty=2)
```


### Conclusiones:

Concluimos tal como lo vimos en clase, que conforme nuestra distribucion a priori es menos informativa, nuestros resultados se ajustan mas a la prediccion y podemos obtener resultados con menor varianza. Partiendo de uno de los propositos de las regresion que es obtener predicciones futuras, queremos buscar las que nos brinden mas confianza a traves de menos sesgo o error en la predicción.




